{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "import nilearn.plotting as nlplt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as anim\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from IPython.display import Image as show_gif\n",
    "\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from skimage.util import montage\n",
    "from skimage.transform import rotate\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "#from volumentations import *\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2 \n",
    "from albumentations import (HorizontalFlip,\n",
    "                            VerticalFlip,\n",
    "                            Normalize,\n",
    "                            Compose)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image3dToGIF3d:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 img_dim: tuple = (55, 55, 55),\n",
    "                 figsize: tuple = (15, 10),\n",
    "                 binary: bool = False,\n",
    "                 normalizing: bool = True,\n",
    "                 is_check_shapes=False,\n",
    "                ):\n",
    "        self.img_dim = img_dim\n",
    "        print(img_dim)\n",
    "        self.figsize = figsize\n",
    "        self.binary = binary\n",
    "        self.normalizing = normalizing\n",
    "\n",
    "    def _explode(self, data: np.ndarray):\n",
    "       \n",
    "        shape_arr = np.array(data.shape)\n",
    "        size = shape_arr[:3] * 2 - 1\n",
    "        exploded = np.zeros(np.concatenate([size, shape_arr[3:]]),\n",
    "                            dtype=data.dtype)\n",
    "        exploded[::2, ::2, ::2] = data\n",
    "        return exploded\n",
    "    \n",
    "    def _expand_coordinates(self, indices: np.ndarray):\n",
    "        x, y, z = indices\n",
    "        x[1::2, :, :] += 1\n",
    "        y[:, 1::2, :] += 1\n",
    "        z[:, :, 1::2] += 1\n",
    "        return x, y, z\n",
    "    \n",
    "    def _normalize(self, arr: np.ndarray):\n",
    "        arr_min = np.min(arr)\n",
    "        return (arr - arr_min) / (np.max(arr) - arr_min)\n",
    "\n",
    "    \n",
    "    def _scale_by(self, arr: np.ndarray, factor: int):\n",
    "        \n",
    "        mean = np.mean(arr)\n",
    "        return (arr - mean) * factor + mean\n",
    "    \n",
    "    def get_transformed_data(self, data: np.ndarray):\n",
    "        if self.binary:\n",
    "            resized_data = resize(data, self.img_dim, preserve_range=True)\n",
    "            return np.clip(resized_data.astype(np.uint8), 0, 1).astype(np.float32)\n",
    "            \n",
    "        norm_data = np.clip(self._normalize(data)-0.1, 0, 1) ** 0.4\n",
    "        scaled_data = np.clip(self._scale_by(norm_data, 2) - 0.1, 0, 1)\n",
    "        resized_data = resize(scaled_data, self.img_dim, preserve_range=True)\n",
    "        \n",
    "        return resized_data\n",
    "    \n",
    "    def plot_cube(self,\n",
    "                  cube,\n",
    "                  title: str = '', \n",
    "                  init_angle: int = 0,\n",
    "                  make_gif: bool = False,\n",
    "                  path_to_save: str = 'filename.gif'\n",
    "                 ):\n",
    "       \n",
    "        if self.binary:\n",
    "            facecolors = cm.winter(cube)\n",
    "            print(\"binary\")\n",
    "        else:\n",
    "            if self.normalizing:\n",
    "                cube = self._normalize(cube)\n",
    "            facecolors = cm.gist_stern(cube)\n",
    "            print(\"not binary\")\n",
    "            \n",
    "        facecolors[:,:,:,-1] = cube\n",
    "        facecolors = self._explode(facecolors)\n",
    "\n",
    "        filled = facecolors[:,:,:,-1] != 0\n",
    "        x, y, z = self._expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "        with plt.style.context(\"dark_background\"):\n",
    "\n",
    "            fig = plt.figure(figsize=self.figsize)\n",
    "            ax = fig.gca(projection='3d')\n",
    "\n",
    "            ax.view_init(30, init_angle)\n",
    "            ax.set_xlim(right = self.img_dim[0] * 2)\n",
    "            ax.set_ylim(top = self.img_dim[1] * 2)\n",
    "            ax.set_zlim(top = self.img_dim[2] * 2)\n",
    "            ax.set_title(title, fontsize=18, y=1.05)\n",
    "\n",
    "            ax.voxels(x, y, z, filled, facecolors=facecolors, shade=False)\n",
    "\n",
    "            if make_gif:\n",
    "                images = []\n",
    "                for angle in tqdm(range(0, 360, 5)):\n",
    "                    ax.view_init(30, angle)\n",
    "                    fname = str(angle) + '.png'\n",
    "\n",
    "                    plt.savefig(fname, dpi=120, format='png', bbox_inches='tight')\n",
    "                    images.append(imageio.imread(fname))\n",
    "                    #os.remove(fname)\n",
    "                imageio.mimsave(path_to_save, images)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "def merging_two_gif(path1: str, path2: str, name_to_save: str):\n",
    "\n",
    "    gif1 = imageio.get_reader(path1)\n",
    "    gif2 = imageio.get_reader(path2)\n",
    "\n",
    "    #If they don't have the same number of frame take the shorter\n",
    "    number_of_frames = min(gif1.get_length(), gif2.get_length()) \n",
    "\n",
    "    #Create writer object\n",
    "    new_gif = imageio.get_writer(name_to_save)\n",
    "\n",
    "    for frame_number in range(number_of_frames):\n",
    "        img1 = gif1.get_next_data()\n",
    "        img2 = gif2.get_next_data()\n",
    "        new_image = np.hstack((img1, img2))\n",
    "        new_gif.append_data(new_image)\n",
    "\n",
    "    gif1.close()\n",
    "    gif2.close()    \n",
    "    new_gif.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalConfig:\n",
    "    root_dir = r'C:\\DATASET_BRAIN_TURMOR\\brats20-dataset-training-validation'\n",
    "    train_root_dir = r'C:\\DATASET_BRAIN_TURMOR\\brats20-dataset-training-validation\\MICCAI_BraTS2020_TrainingData'\n",
    "    test_root_dir = r'C:\\DATASET_BRAIN_TURMOR\\BraTS2020_ValidationData\\MICCAI_BraTS2020_ValidationData'\n",
    "    path_to_csv = r'C:\\DATASET_BRAIN_TURMOR\\last\\train_data.csv'\n",
    "    ae_pretrained_model_path = r\"C:\\Users\\Storbiiic\\Downloads\\archive (1)\\brats2020logs\\ae\\autoencoder_best_model.pth\"\n",
    "    pretrained_model_path = r'C:\\DATASET_BRAIN_TURMOR\\last\\last_epoch_model_modified11.pth'\n",
    "    train_logs_path = r'C:\\DATASET_BRAIN_TURMOR\\last\\train_log_modified11.csv'\n",
    "    seed = 55\n",
    "    is_check_shapes=False\n",
    "    \n",
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "config = GlobalConfig()\n",
    "seed_everything(config.seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df -> (117, 11) val_df -> (118, 11) test_df -> (133, 10)\n"
     ]
    }
   ],
   "source": [
    "survival_info_df = pd.read_csv(r'C:\\DATASET_BRAIN_TURMOR\\brats20-dataset-training-validation\\MICCAI_BraTS2020_TrainingData\\survival_info.csv')\n",
    "name_mapping_df = pd.read_csv(r'C:\\DATASET_BRAIN_TURMOR\\brats20-dataset-training-validation\\MICCAI_BraTS2020_TrainingData\\name_mapping.csv')\n",
    "\n",
    "name_mapping_df.rename({'BraTS_2020_subject_ID': 'Brats20ID'}, axis=1, inplace=True) \n",
    "\n",
    "\n",
    "df = survival_info_df.merge(name_mapping_df, on=\"Brats20ID\", how=\"right\")\n",
    "\n",
    "paths = []\n",
    "for index, row  in df.iterrows():\n",
    "    \n",
    "    id_ = row['Brats20ID']\n",
    "    phase = id_.split(\"_\")[-2]\n",
    "    \n",
    "    if phase == 'Training':\n",
    "        path = os.path.join(config.train_root_dir, id_)\n",
    "    else:\n",
    "        path = os.path.join(config.test_root_dir, id_)\n",
    "    paths.append(path)\n",
    "    \n",
    "df['path'] = paths\n",
    "\n",
    "train_data = df.loc[df['Age'].notnull()].reset_index(drop=True)\n",
    "train_data = train_data.loc[train_data['Brats20ID'] != 'BraTS20_Training_355'].reset_index(drop=True, ) #eliminam pacientul 355 deoarece formatul nu este bun\n",
    "\n",
    "# impartim data in antrenare (train), validare (val) si evaluare (test)\n",
    "skf = StratifiedKFold(n_splits=2, random_state=config.seed, shuffle=True) #impartim setul de date in 7 parti folosind un seed pentru a obtine mereu aceeasi ordine\n",
    "for i, (train_index, val_index) in enumerate(skf.split(train_data, train_data[\"Age\"]//10*10)):\n",
    "        train_data.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train_df = train_data.loc[train_data['fold'] != 0].reset_index(drop=True)\n",
    "val_df = train_data.loc[train_data['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "test_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\n",
    "print(\"train_df ->\", train_df.shape, \"val_df ->\", val_df.shape, \"test_df ->\", test_df.shape)\n",
    "train_data.to_csv(\"train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2877451\n",
      "13244475\n",
      "5250041\n",
      "2076708033\n",
      "2098080000\n"
     ]
    }
   ],
   "source": [
    "def load_img1(file_path):\n",
    "    data = nib.load(file_path)\n",
    "    return data\n",
    "tumor_core_total=0\n",
    "peritumoral_edema_total=0\n",
    "enhancing_tumor_total=0\n",
    "num_zeros_total=0\n",
    "for idx in train_data['Brats20ID']:\n",
    "    root_path = train_data.loc[train_data['Brats20ID'] == idx]['path'].values[0] # preluam calea din fisierul csv\n",
    "    img_path = os.path.join(root_path +'/' + idx+  '_seg.nii')\n",
    "    img = load_img1(img_path)\n",
    "    a = np.array(img.dataobj)\n",
    "    b=a.flatten()\n",
    "\n",
    "    tumor_core=np.count_nonzero(b == 1)\n",
    "    tumor_core_total=tumor_core_total+tumor_core\n",
    "    \n",
    "    peritumoral_edema=np.count_nonzero(b==2)\n",
    "    peritumoral_edema_total=peritumoral_edema_total+peritumoral_edema\n",
    "    \n",
    "    enhancing_tumor=np.count_nonzero(b==4)\n",
    "    enhancing_tumor_total=enhancing_tumor_total+enhancing_tumor\n",
    "    \n",
    "    num_zeros = (b == 0).sum()\n",
    "    num_zeros_total=num_zeros_total+num_zeros\n",
    "print(tumor_core_total)\n",
    "print(peritumoral_edema_total)\n",
    "print(enhancing_tumor_total)\n",
    "print(num_zeros_total)\n",
    "print(tumor_core_total+peritumoral_edema_total+enhancing_tumor_total+num_zeros_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_center_crop_coords(height, width, depth, crop_height, crop_width, crop_depth):\n",
    "                x1 = (height - crop_height) // 2\n",
    "                x2 = x1 + crop_height\n",
    "                y1 = (width - crop_width) // 2\n",
    "                y2 = y1 + crop_width\n",
    "                z1 = (depth - crop_depth) // 2\n",
    "                z2 = z1 + crop_depth\n",
    "                return x1, y1, z1, x2, y2, z2\n",
    "\n",
    "def center_crop(data:np.ndarray, crop_height, crop_width, crop_depth):\n",
    "    height, width, depth = data.shape[:3]\n",
    "    if height < crop_height or width < crop_width or depth < crop_depth:\n",
    "        raise ValueError\n",
    "    x1, y1, z1, x2, y2, z2 = get_center_crop_coords(height, width, depth, crop_height, crop_width, crop_depth)\n",
    "    data = data[x1:x2, y1:y2, z1:z2]\n",
    "    return data\n",
    "\n",
    "def load_img1(file_path):\n",
    "    data = nib.load(file_path)\n",
    "    return data\n",
    "tumor_core_total=0\n",
    "peritumoral_edema_total=0\n",
    "enhancing_tumor_total=0\n",
    "num_zeros_total=0\n",
    "for idx in train_data['Brats20ID']:\n",
    "    root_path = train_data.loc[train_data['Brats20ID'] == idx]['path'].values[0] # preluam calea din fisierul csv\n",
    "    img_path = os.path.join(root_path +'/' + idx+  '_seg.nii')\n",
    "    img = load_img1(img_path)\n",
    "    a = np.array(img.dataobj)\n",
    "    get_center_crop_coords(240,240,155, 128,128,128)\n",
    "    a=center_crop(a, 128,128,128)\n",
    "    plt.imshow(a[10])\n",
    "    plt.show()\n",
    "    plt.savefig('foo.png')\n",
    "    print(a.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1449588\n",
      "6556121\n",
      "2518182\n",
      "1042980109\n"
     ]
    }
   ],
   "source": [
    "def load_img1(file_path):\n",
    "    data = nib.load(file_path)\n",
    "    return data\n",
    "tumor_core_total=0\n",
    "peritumoral_edema_total=0\n",
    "enhancing_tumor_total=0\n",
    "num_zeros_total=0\n",
    "\n",
    "for idx in val_df['Brats20ID']:\n",
    "    root_path = val_df.loc[val_df['Brats20ID'] == idx]['path'].values[0] # preluam calea din fisierul csv\n",
    "    img_path = os.path.join(root_path +'/' + idx+  '_seg.nii')\n",
    "    img = load_img1(img_path)\n",
    "    a = np.array(img.dataobj)\n",
    "    b=a.flatten()\n",
    "#     unique, counts = np.unique(b, return_counts=True)\n",
    "#     dict(zip(unique, counts))\n",
    "    tumor_core=np.count_nonzero(b == 1)\n",
    "    tumor_core_total=tumor_core_total+tumor_core\n",
    "    \n",
    "    peritumoral_edema=np.count_nonzero(b==2)\n",
    "    peritumoral_edema_total=peritumoral_edema_total+peritumoral_edema\n",
    "    \n",
    "    enhancing_tumor=np.count_nonzero(b==4)\n",
    "    enhancing_tumor_total=enhancing_tumor_total+enhancing_tumor\n",
    "    \n",
    "    num_zeros = (b == 0).sum()\n",
    "    num_zeros_total=num_zeros_total+num_zeros\n",
    "print(tumor_core_total)\n",
    "print(peritumoral_edema_total)\n",
    "print(enhancing_tumor_total)\n",
    "print(num_zeros_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3DAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv3d(4, 16, 3)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv3d(32, 96, 2)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=3, stride=3, return_indices=True)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.enc_linear = nn.Linear(381216, 512)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose3d(96, 32, 2)\n",
    "        self.deconv2 = nn.ConvTranspose3d(32, 16, 3)\n",
    "        self.deconv3 = nn.ConvTranspose3d(16, 4, 3)\n",
    "        self.unpool1 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
    "        self.unpool2 = nn.MaxUnpool3d(kernel_size=3, stride=3)\n",
    "        self.unpool3 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dec_linear = nn.Linear(512, 381216)\n",
    "        \n",
    "    def encode(self, x, return_partials=True):\n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        up3out_shape = x.shape\n",
    "        x, indices1 = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        up2out_shape = x.shape\n",
    "        x, indices2 = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        up1out_shape = x.shape\n",
    "        x, indices3 = self.pool3(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view((x.size(0), -1))\n",
    "        #print(x.shape)\n",
    "        x = self.enc_linear(x)\n",
    "\n",
    "        # required for unpool\n",
    "        pool_par = {\n",
    "            \"P1\": [indices1, up3out_shape], \n",
    "            \"P2\": [indices2, up2out_shape], \n",
    "            \"P3\": [indices3, up1out_shape]\n",
    "                   }\n",
    "        \n",
    "        if return_partials:\n",
    "            return x, pool_par\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def decode(self, x, pool_par):\n",
    "        x = self.dec_linear(x)\n",
    "        x = x.view((x.size(0), 96, 11, 19, 19))\n",
    "        \n",
    "        x = self.unpool1(x, output_size=pool_par[\"P3\"][1], indices=pool_par[\"P3\"][0])\n",
    "        #print(x.shape)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.unpool2(x, output_size=pool_par[\"P2\"][1], indices=pool_par[\"P2\"][0])\n",
    "        x = self.deconv2(x)\n",
    "        x = self.unpool3(x, output_size=pool_par[\"P1\"][1], indices=pool_par[\"P1\"][0])\n",
    "        x = self.deconv3(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.feature, pool_par = self.encode(x)\n",
    "        out = self.decode(self.feature, pool_par)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentations(phase):\n",
    "    list_transforms = []\n",
    "    \n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "\n",
    "def get_dataloader(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    path_to_csv: str,\n",
    "    phase: str,\n",
    "    fold: int = 0,\n",
    "    batch_size: int = 1,\n",
    "    num_workers: int = 0,\n",
    "):\n",
    "    '''Returns: dataloader for the model training'''\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    \n",
    "    train_df = df.loc[df['fold'] != fold].reset_index(drop=True)\n",
    "    val_df = df.loc[df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    dataset = dataset(df, phase)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, phase: str = \"test\"):\n",
    "        self.df = df\n",
    "        self.phase = phase\n",
    "        self.augmentations = get_augmentations(phase)\n",
    "        self.data_types = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        id_ = self.df.loc[idx, 'Brats20ID']\n",
    "        root_path = self.df.loc[self.df['Brats20ID'] == id_]['path'].values[0]\n",
    "        # load all modalities\n",
    "        images = []\n",
    "        for data_type in self.data_types:\n",
    "            img_path = os.path.join(root_path, id_ + data_type)\n",
    "            img = self.load_img(img_path)\n",
    "\n",
    "            img = self.normalize(img)\n",
    "            images.append(img.astype(np.float32))\n",
    "        img = np.stack(images)\n",
    "        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "    \n",
    "        \n",
    "        return {\n",
    "            \"Id\": id_,\n",
    "            \"data\": img,\n",
    "            \"label\": img,\n",
    "            }\n",
    "    \n",
    "    def load_img(self, file_path):\n",
    "        data = nib.load(file_path)\n",
    "        data = np.asarray(data.dataobj)\n",
    "        return data\n",
    "    \n",
    "    def normalize(self, data: np.ndarray,  mean=0.0, std=1.0):\n",
    "        \"\"\"Normilize image value between 0 and 1.\"\"\"\n",
    "        data_min = np.min(data)\n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = get_dataloader(dataset=AutoEncoderDataset, path_to_csv='train_data.csv', phase='valid', fold=0,num_workers=0)\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['BraTS20_Training_353'],\n",
       " torch.Size([1, 4, 155, 240, 240]),\n",
       " torch.Size([1, 4, 155, 240, 240]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(dataloader))\n",
    "data['Id'], data['data'].shape, data['label'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 net: nn.Module,\n",
    "                 criterion: nn.Module,\n",
    "                 lr: float,\n",
    "                 accumulation_steps: int,\n",
    "                 batch_size: int,\n",
    "                 fold: int,\n",
    "                 num_epochs: int,\n",
    "                 path_to_csv: str,\n",
    "                 dataset: torch.utils.data.Dataset,\n",
    "                ):\n",
    "\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.device = 'cpu' #if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"device:\", self.device)\n",
    "        self.net = net\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = Adam(self.net.parameters(), lr=lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\",\n",
    "                                           patience=2, verbose=True)\n",
    "        self.accumulation_steps = accumulation_steps // batch_size\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        self.dataloaders = {\n",
    "\n",
    "            phase: get_dataloader(\n",
    "                dataset = dataset,\n",
    "                path_to_csv = path_to_csv,\n",
    "                phase = phase,\n",
    "                fold = fold,\n",
    "                batch_size = batch_size,\n",
    "                num_workers = 4\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "         \n",
    "    def _compute_loss_and_outputs(self,\n",
    "                                  images: torch.Tensor,\n",
    "                                  targets: torch.Tensor):\n",
    "        images = images.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "        logits = self.net(images)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        return loss, logits\n",
    "        \n",
    "    def _do_epoch(self, epoch: int, phase: str):\n",
    "        print(f\"{phase} epoch: {epoch} | time: {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "        self.net.train() if phase == \"train\" else self.net.eval()\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        total_batches = len(dataloader)\n",
    "        running_loss = 0.0\n",
    "        self.optimizer.zero_grad()\n",
    "        for itr, data_batch in enumerate(dataloader):\n",
    "            images, targets = data_batch['data'], data_batch['label']\n",
    "            loss, logits = self._compute_loss_and_outputs(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "\n",
    "        \n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        print(f\"Loss | {self.losses[phase][-1]}\")\n",
    "\n",
    "\n",
    "        return epoch_loss\n",
    "        \n",
    "    def run(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self._do_epoch(epoch, \"train\")\n",
    "            with torch.no_grad():\n",
    "                val_loss = self._do_epoch(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "                \n",
    "            if val_loss < self.best_loss:\n",
    "                print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n",
    "                self.best_loss = val_loss\n",
    "                torch.save(self.net.state_dict(), \"autoencoder_best_model.pth\")\n",
    "            print()\n",
    "        self._save_train_history()\n",
    "            \n",
    "            \n",
    "    def load_predtrain_model(self,\n",
    "                             state_path: str):\n",
    "        self.net.load_state_dict(torch.load(state_path))\n",
    "        print(\"Predtrain model loaded\")\n",
    "        \n",
    "    def _save_train_history(self):\n",
    "        \"\"\"writing model weights and training logs to files.\"\"\"\n",
    "        torch.save(self.net.state_dict(),\n",
    "                   f\"autoencoder_last_epoch_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:768\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "Predtrain model loaded\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder().to('cuda')\n",
    "\n",
    "trainer = Trainer(net=model,\n",
    "                  dataset= AutoEncoderDataset,\n",
    "                  criterion=MSELoss(),\n",
    "                  lr=5e-4,\n",
    "                  accumulation_steps=4,\n",
    "                  batch_size=1,\n",
    "                  fold=0,\n",
    "                  num_epochs=1,\n",
    "                  path_to_csv = config.path_to_csv,)\n",
    "\n",
    "\n",
    "if config.ae_pretrained_model_path is not None:\n",
    "    trainer.load_predtrain_model(config.ae_pretrained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0 | time: 23:29:53\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 5692, 4500, 5756, 9700) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Storbiiic\\anaconda3\\envs\\tf1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Storbiiic\\anaconda3\\envs\\tf1\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_empty\u001b[39m.\u001b[39mwait(remaining)\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "\u001b[1;32mc:\\DATASET_BRAIN_TURMOR\\3dAutoEncoder_tryout.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch(epoch, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m         \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m             val_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_epoch(epoch, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\DATASET_BRAIN_TURMOR\\3dAutoEncoder_tryout.ipynb Cell 20\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mfor\u001b[39;00m itr, data_batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     images, targets \u001b[39m=\u001b[39m data_batch[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m], data_batch[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/DATASET_BRAIN_TURMOR/3dAutoEncoder_tryout.ipynb#X25sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     loss, logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_loss_and_outputs(images, targets)\n",
      "File \u001b[1;32mc:\\Users\\Storbiiic\\anaconda3\\envs\\tf1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Storbiiic\\anaconda3\\envs\\tf1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Storbiiic\\anaconda3\\envs\\tf1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m   1283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[1;32m-> 1284\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1285\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1286\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Storbiiic\\anaconda3\\envs\\tf1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 5692, 4500, 5756, 9700) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking quality of AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(AutoEncoderDataset, 'train_data.csv', phase='val', fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        id_, imgs, targets = data['Id'], data['data'], data['label']\n",
    "        imgs, targets = imgs.to('cuda'), targets.to('cuda')\n",
    "        output = model(imgs)\n",
    "        output = output.cpu()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.squeeze().cpu().numpy()\n",
    "imgs = np.moveaxis(imgs, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "print(imgs.shape)\n",
    "\n",
    "gt_flair, gt_t1, gt_t1ce, gt_t2 = imgs\n",
    "print(gt_flair.shape, gt_t1.shape, gt_t1ce.shape, gt_t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(np.rot90(montage(gt_flair)), cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "title = \"AE_Ground_Truth_\" + id_[0]\n",
    "filename1 = title + \"_3d.gif\"\n",
    "\n",
    "\n",
    "data_to_3dgif = Image3dToGIF3d(img_dim = (55, 55, 55), binary=False, normalizing=False)\n",
    "transformed_data = data_to_3dgif.get_transformed_data(gt_flair)\n",
    "#transformed_data = np.rot90(transformed_data)\n",
    "data_to_3dgif.plot_cube(\n",
    "    transformed_data[:38, :47, :35],\n",
    "    title=title,\n",
    "    make_gif=True,\n",
    "    path_to_save=filename1\n",
    ")\n",
    "#show_gif(filename1, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze().numpy()\n",
    "output = np.moveaxis(output, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "print(output.shape)\n",
    "\n",
    "pr_flair, pr_t1, pr_t1ce, pr_t2 = output\n",
    "print(pr_flair.shape, pr_t1.shape, pr_t1ce.shape, pr_t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "pr_flair1 = pr_flair.copy()\n",
    "pr_flair1[pr_flair1 < 1e-7] = 0  # remove artifacts.\n",
    "plt.imshow(np.rot90(montage(pr_flair1)), cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "title = \"AE_Prediction_\" + id_[0]\n",
    "filename2 = title + \"_3d.gif\"\n",
    "\n",
    "\n",
    "data_to_3dgif = Image3dToGIF3d(img_dim = (55, 55, 55), binary=False, normalizing=False)\n",
    "transformed_data = data_to_3dgif.get_transformed_data(pr_flair1)\n",
    "#transformed_data = np.rot90(transformed_data)\n",
    "data_to_3dgif.plot_cube(\n",
    "    transformed_data[:38, :47, :35],\n",
    "    title=title,\n",
    "    make_gif=True,\n",
    "    path_to_save=filename2\n",
    ")\n",
    "#show_gif(filename1, format='png')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_two_gif(filename1,\n",
    "                filename2, \n",
    "                'AE_result.gif')\n",
    "show_gif('AE_result.gif', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generates all latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFeaturesGenerator:\n",
    "    def __init__(self, \n",
    "                 autoencoder, \n",
    "                 device: str = 'cuda'):\n",
    "        \n",
    "        self.autoencoder = autoencoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, img):\n",
    "        with torch.no_grad():\n",
    "            img = torch.FloatTensor(img).unsqueeze(0).to(self.device)\n",
    "            latent_features = self.autoencoder.encode(\n",
    "                img, return_partials=False).squeeze(0).cpu().numpy()\n",
    "\n",
    "        return latent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features_Generator:\n",
    "    \n",
    "    def __init__(self, df, autoencoder):\n",
    "        self.df = df\n",
    "        self.df_voxel_stats = pd.DataFrame()\n",
    "        self.latent_feature_generator = LatentFeaturesGenerator(autoencoder)\n",
    "        \n",
    "    def _read_file(self, file_path):\n",
    "        data = nib.load(file_path)\n",
    "        data = np.asarray(data.dataobj).astype(np.float32)\n",
    "        return data\n",
    "    \n",
    "    def _normalize(self, data: np.ndarray):\n",
    "        \"\"\"Normilize image value between 0 and 1.\"\"\"\n",
    "        data_min = np.min(data)\n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "    \n",
    "    def _create_features(self, Brats20ID):\n",
    "        features = {}\n",
    "        images = []\n",
    "        # vOXEL STATS\n",
    "        for data_type in ['_t1.nii', '_t2.nii', '_flair.nii', '_t1ce.nii']:\n",
    "            \n",
    "            \n",
    "            # data path\n",
    "            root_path = self.df.loc[self.df['Brats20ID'] == Brats20ID]['path'].values[0]\n",
    "            file_path = os.path.join(root_path, Brats20ID + data_type)\n",
    "            \n",
    "            # flatten 3d array\n",
    "            img_data = self._read_file(file_path)\n",
    "            data = img_data.reshape(-1)\n",
    "            \n",
    "            # create features\n",
    "            data_mean = data.mean()\n",
    "            data_std = data.std()\n",
    "            intensive_data = data[data > data_mean]\n",
    "            more_intensive_data = data[data > data_mean + data_std]\n",
    "            non_intensive_data = data[data < data_mean]\n",
    "            \n",
    "            data_skew = stats.skew(data)\n",
    "            data_kurtosis = stats.kurtosis(data)\n",
    "            intensive_skew = stats.skew(intensive_data)\n",
    "            non_intensive_skew = stats.skew(non_intensive_data)\n",
    "            \n",
    "            data_diff = np.diff(data)\n",
    "            \n",
    "            # write new features in df\n",
    "            features['Brats20ID'] = Brats20ID\n",
    "            features[f'{data_type}_skew'] = data_skew,\n",
    "            features[f'{data_type}_kurtosis'] = data_kurtosis,\n",
    "            features[f'{data_type}_diff_skew'] = stats.skew(data_diff),\n",
    "            features[f'{data_type}_intensive_dist'] = intensive_data.shape[0],\n",
    "            features[f'{data_type}_intensive_skew'] = intensive_skew,\n",
    "            features[f'{data_type}_non_intensive_dist'] = non_intensive_data.shape[0],\n",
    "            features[f'{data_type}_non_intensive_skew'] = non_intensive_skew,\n",
    "            #features[f'{data_type}_intensive_non_intensive_mean_ratio'] = intensive_data.mean() / non_intensive_data.mean(),\n",
    "            #features[f'{data_type}_intensive_non_intensive_std_ratio'] = intensive_data.std() / non_intensive_data.std(),\n",
    "            features[f'{data_type}_data_intensive_skew_difference'] = data_skew - intensive_skew,\n",
    "            features[f'{data_type}_data_non_intensive_skew_difference'] = data_skew - non_intensive_skew,\n",
    "            features[f'{data_type}_more_intensive_dist'] = more_intensive_data.shape[0],\n",
    "            \n",
    "            parts = 15\n",
    "            for p, part in enumerate(np.array_split(data, parts)):\n",
    "                features[f'{data_type}_part{p}_mean'] = part.mean()\n",
    "                \n",
    "            # Latent Features    \n",
    "            img = self._normalize(img_data)\n",
    "            images.append(img.astype(np.float32))\n",
    "            \n",
    "        img = np.stack(images)\n",
    "        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "        latent_features = self.latent_feature_generator(img)\n",
    "        \n",
    "        for i, lf in enumerate(latent_features):\n",
    "                features[f'latent_f{i}'] = lf\n",
    "          \n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        for _, row in tqdm(self.df.iterrows()):\n",
    "            ID = row['Brats20ID']\n",
    "            \n",
    "            df_features = self._create_features(ID)\n",
    "            \n",
    "            self.df_voxel_stats  = pd.concat([self.df_voxel_stats, df_features], axis=0) \n",
    "            \n",
    "        self.df_voxel_stats.reset_index(inplace=True, drop=True) \n",
    "        self.df_voxel_stats = self.df_voxel_stats.merge(self.df[['Brats20ID', 'Age', 'Survival_days']], on='Brats20ID', how='left')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.eval();\n",
    "fg =  Features_Generator(df, model)\n",
    "fg.run()\n",
    "fg.df_voxel_stats.to_csv(\"df_with_voxel_stats_and_latent_features.csv\", index=False)\n",
    "fg.df_voxel_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tabular data, we can use it to predict age and survival days.\n",
    "we will use SVR for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_with_voxel_stats_and_latent_features.csv\")#\n",
    "\n",
    "df['is_train'] = 0\n",
    "df['is_train'].loc[df['Survival_days'].notnull()] = 1\n",
    "\n",
    "df['SD'] = df['Survival_days'].str.extract(r'(\\d+[.\\d]*)')\n",
    "df['SD'] = df['SD'].astype(\"float64\")\n",
    "df['Age'] = df['Age'].astype(\"float64\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df[\"is_train\"] != True].copy()\n",
    "df = df[df[\"is_train\"] == True].copy()\n",
    "print(\"train ->\", df.shape, \"test ->\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.countplot(df['Age'].apply(lambda x: np.round(x, 0)), ax=ax, palette='Dark2')\n",
    "\n",
    "ax.set_xticks(ax.get_xticks()[::2]);\n",
    "ax.set_ylabel('number of unique (rounded) ages', fontsize=20)\n",
    "ax.set_xlabel('unique (rounded) ages', fontsize=20)\n",
    "ax.set_title(\"Distribution of rounded Ages in data\", fontsize=25, y=1.05, fontweight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "k = 10\n",
    "sns.countplot(df['SD'].apply(lambda x: int(k * round(float(x)/k))), ax=ax, palette='Dark2')#base * round(float(x)/base)\n",
    "\n",
    "ax.set_xticks(ax.get_xticks()[::2]);\n",
    "ax.set_ylabel('number of unique (rounding to the nearest {k}) Survival_days', fontsize=15)\n",
    "ax.set_xlabel(f'unique (rounding to the nearest {k}) Survival_days', fontsize=17)\n",
    "ax.set_title(\"Distribution of rounded Survival_days in data\", fontsize=25, y=1.05, fontweight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "NUM_FOLDS = 2\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=config.seed)\n",
    "\n",
    "\n",
    "features = list(df.columns[1:-4])\n",
    "\n",
    "overal_score = 0\n",
    "for target, c, w in [(\"Age\", 100, 0.5), (\"SD\", 5, 0.5)]:    \n",
    "    y_oof = np.zeros(df.shape[0])\n",
    "    y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n",
    "    \n",
    "    for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n",
    "        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n",
    "        train_df = train_df[train_df[target].notnull()]\n",
    "\n",
    "        model = SVR(C=c, cache_size=3000.0)\n",
    "        model.fit(train_df[features], train_df[target])\n",
    "\n",
    "        y_oof[val_ind] = model.predict(val_df[features])\n",
    "        y_test[:, f] = model.predict(test_df[features])\n",
    "        \n",
    "    df[\"pred_{}\".format(target)] = y_oof\n",
    "    test_df[target] = y_test.mean(axis=1)\n",
    "    score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n",
    "    overal_score += w*score\n",
    "    print(target, np.round(score, 4))\n",
    "    print()\n",
    "    \n",
    "print(\"Overal score:\", np.round(overal_score, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
